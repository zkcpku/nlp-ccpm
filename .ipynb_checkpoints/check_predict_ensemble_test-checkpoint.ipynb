{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72087f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMultipleChoice,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "import numpy as np\n",
    "# np.argmax([1,2,3,4])\n",
    "def softmax(x, axis=None):\n",
    "    x = np.array(x)\n",
    "    x = x - x.max(axis=axis, keepdims=True)\n",
    "    y = np.exp(x)\n",
    "    rst = y / y.sum(axis=axis, keepdims=True)\n",
    "    return rst.tolist()\n",
    "softmax([1,2])\n",
    "tokenizer = AutoTokenizer.from_pretrained('ethanyt/guwenbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af0713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/test_placeholder.jsonl','r') as f:\n",
    "    valid_json = f.readlines()\n",
    "    valid_json = [json.loads(e) for e in valid_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "798cc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(predict_valid_json,out_path):\n",
    "    with open(out_path,'w') as f:\n",
    "        for line in predict_valid_json:\n",
    "            this_line = {'translation':line['translation'],'choices':line['choices'],'answer':int(line['predict'])}\n",
    "            f.write(json.dumps(this_line,ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715fe30",
   "metadata": {},
   "source": [
    "### ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f03b4919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 10880/10880 [00:07<00:00, 1463.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/test/ner.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for batch_idx in tqdm(range(len(rst['test_dataset']))):\n",
    "    origin_id = rst['test_dataset'][batch_idx]['origin_idx']\n",
    "    if origin_id not in all_scores:\n",
    "        all_scores[origin_id] = []\n",
    "    predicts = softmax(rst['test_result'].predictions[batch_idx],axis=-1)\n",
    "    labels = rst['test_result'].label_ids[batch_idx]\n",
    "    all_scores[origin_id].append(np.array(predicts)[np.where(labels!=-100)[0].tolist()][:,1].tolist())\n",
    "def multiple_list(l):\n",
    "    rst = 1\n",
    "    for e in l:\n",
    "        rst *= e\n",
    "    return rst\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = []\n",
    "    for choice_id in range(len(choices)):\n",
    "        choice_score = all_scores[i][choice_id]\n",
    "        choice_score = multiple_list(choice_score)\n",
    "#         choice_score = sum(choice_score)\n",
    "        this_scores.append(choice_score)\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202bbfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25882352941176473"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72b7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cc101",
   "metadata": {},
   "source": [
    "### binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "199e87a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 24749/24749 [00:10<00:00, 2461.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2584558823529412"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/test/binary.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for i in tqdm(range(len(rst['test_dataset']))):\n",
    "    idx = rst['test_dataset'][i]['origin_idx']\n",
    "    input_str = rst['test_dataset'][i]['input_ids']\n",
    "    input_str = tokenizer.decode(input_str)\n",
    "    input_str = input_str.split('[SEP]')\n",
    "    if idx not in all_scores:\n",
    "        all_scores[idx] = {}\n",
    "    all_scores[idx][input_str[1].replace(' ','')] = softmax(rst['test_result'].predictions[i].tolist())\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = []\n",
    "    for choice in choices:\n",
    "        choice_score = 0\n",
    "        for k in all_scores[i]:\n",
    "            if k in choice:\n",
    "                choice_score += all_scores[i][k][1]\n",
    "        this_scores.append(choice_score)\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69ee8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dee95f",
   "metadata": {},
   "source": [
    "### seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21d24b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 2720/2720 [00:00<00:00, 52184.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2610294117647059"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/test/seq.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for i in tqdm(range(len(rst['test_dataset']))):\n",
    "    idx = i\n",
    "    all_scores[idx] = softmax(rst['test_result'].predictions[i].tolist())\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = all_scores[i]\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0809019",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d98290",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b959075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 2720/2720 [00:00<00:00, 32554.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2613970588235294"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/test/baseline.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for i in tqdm(range(len(rst['test_dataset']))):\n",
    "    idx = i\n",
    "    all_scores[idx] = softmax(rst['test_result'].predictions[i].tolist())\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = all_scores[i]\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0dd623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c989b62",
   "metadata": {},
   "source": [
    "### save_each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb72f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(ner_predict,'predict/final/test/ner.jsonl')\n",
    "save_jsonl(binary_predict,'predict/final/test/binary.jsonl')\n",
    "save_jsonl(seq_predict,'predict/final/test/seq.jsonl')\n",
    "save_jsonl(baseline_predict,'predict/final/test/baseline.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ac0f3",
   "metadata": {},
   "source": [
    "### ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e6672fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3290441176470588\n"
     ]
    }
   ],
   "source": [
    "oracle_true = [binary_predict[i]['true'] or ner_predict[i]['true'] or seq_predict[i]['true'] for i in range(len(ner_predict))]\n",
    "oracle_true = sum(oracle_true) / len(oracle_true)\n",
    "print(oracle_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09761171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26176470588235295\n"
     ]
    }
   ],
   "source": [
    "w = [1,0.1,1.6]\n",
    "predict_list = [ner_predict,binary_predict,seq_predict]\n",
    "ensemble_predict = []\n",
    "def get_score(w,predict_list):\n",
    "    ensemble_predict = []\n",
    "    for i in range(len(predict_list[0])):\n",
    "        ensemble_predict.append(predict_list[0][i].copy())\n",
    "        ensemble_predict[-1]['scores'] = [np.array(predict_list[each_ensemble][i]['scores']) * w[each_ensemble] \n",
    "                                          for each_ensemble in range(len(predict_list))]\n",
    "        ensemble_predict[-1]['scores'] = sum(ensemble_predict[-1]['scores']).tolist()\n",
    "        ensemble_predict[-1]['predict'] = np.argmax(ensemble_predict[-1]['scores'])\n",
    "        ensemble_predict[-1]['true'] = (ensemble_predict[-1]['predict'] == ensemble_predict[-1]['answer'])\n",
    "    return np.sum([int(e['true']) for e in ensemble_predict]) / len(ensemble_predict),ensemble_predict\n",
    "rst,ensemble_predict = get_score(w,predict_list)\n",
    "print(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61f830a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(ensemble_predict,'predict/final/test/ensemble.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75a62815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0   0.8580882352941176\n",
      "0.1   0.8801470588235294\n",
      "0.2   0.88125\n",
      "0.30000000000000004   0.8849264705882353\n",
      "0.4   0.8852941176470588\n",
      "0.5   0.8849264705882353\n",
      "0.6000000000000001   0.8871323529411764\n",
      "0.7000000000000001   0.8856617647058823\n",
      "0.8   0.8863970588235294\n",
      "0.9   0.8871323529411764\n",
      "1.0   0.8856617647058823\n",
      "1.1   0.8856617647058823\n",
      "1.2000000000000002   0.8863970588235294\n",
      "1.3   0.8863970588235294\n",
      "1.4000000000000001   0.8871323529411764\n",
      "1.5   0.8867647058823529\n",
      "1.6   0.8871323529411764\n",
      "1.7000000000000002   0.8871323529411764\n",
      "1.8   0.8867647058823529\n",
      "1.9000000000000001   0.8867647058823529\n",
      "2.0   0.8867647058823529\n",
      "2.1   0.8863970588235294\n",
      "2.2   0.8863970588235294\n",
      "2.3000000000000003   0.8863970588235294\n",
      "2.4000000000000004   0.8863970588235294\n",
      "2.5   0.8856617647058823\n",
      "2.6   0.8856617647058823\n",
      "2.7   0.8856617647058823\n",
      "2.8000000000000003   0.8856617647058823\n",
      "2.9000000000000004   0.8856617647058823\n",
      "3.0   0.8856617647058823\n",
      "3.1   0.8856617647058823\n",
      "3.2   0.8856617647058823\n",
      "3.3000000000000003   0.8856617647058823\n",
      "3.4000000000000004   0.8852941176470588\n",
      "3.5   0.8852941176470588\n",
      "3.6   0.8852941176470588\n",
      "3.7   0.8852941176470588\n",
      "3.8000000000000003   0.8849264705882353\n",
      "3.9000000000000004   0.8849264705882353\n",
      "4.0   0.8849264705882353\n",
      "4.1000000000000005   0.8849264705882353\n",
      "4.2   0.8849264705882353\n",
      "4.3   0.8845588235294117\n",
      "4.4   0.8845588235294117\n",
      "4.5   0.8845588235294117\n",
      "4.6000000000000005   0.8845588235294117\n",
      "4.7   0.8841911764705882\n",
      "4.800000000000001   0.8841911764705882\n",
      "4.9   0.8841911764705882\n",
      "5.0   0.8841911764705882\n",
      "5.1000000000000005   0.8841911764705882\n",
      "5.2   0.8841911764705882\n",
      "5.300000000000001   0.8841911764705882\n",
      "5.4   0.8841911764705882\n",
      "5.5   0.8841911764705882\n",
      "5.6000000000000005   0.8841911764705882\n",
      "5.7   0.8838235294117647\n",
      "5.800000000000001   0.8838235294117647\n",
      "5.9   0.8838235294117647\n",
      "6.0   0.8838235294117647\n",
      "6.1000000000000005   0.8838235294117647\n",
      "6.2   0.8838235294117647\n",
      "6.300000000000001   0.8838235294117647\n",
      "6.4   0.8838235294117647\n",
      "6.5   0.8838235294117647\n",
      "6.6000000000000005   0.8838235294117647\n",
      "6.7   0.8838235294117647\n",
      "6.800000000000001   0.8838235294117647\n",
      "6.9   0.8838235294117647\n",
      "7.0   0.8838235294117647\n",
      "7.1000000000000005   0.8838235294117647\n",
      "7.2   0.8838235294117647\n",
      "7.300000000000001   0.8838235294117647\n",
      "7.4   0.8838235294117647\n",
      "7.5   0.8838235294117647\n",
      "7.6000000000000005   0.8838235294117647\n",
      "7.7   0.8838235294117647\n",
      "7.800000000000001   0.8838235294117647\n",
      "7.9   0.8838235294117647\n",
      "8.0   0.8838235294117647\n",
      "8.1   0.8838235294117647\n",
      "8.200000000000001   0.8838235294117647\n",
      "8.3   0.8838235294117647\n",
      "8.4   0.8838235294117647\n",
      "8.5   0.8838235294117647\n",
      "8.6   0.8838235294117647\n",
      "8.700000000000001   0.8838235294117647\n",
      "8.8   0.8838235294117647\n",
      "8.9   0.8838235294117647\n",
      "9.0   0.8838235294117647\n",
      "9.1   0.8838235294117647\n",
      "9.200000000000001   0.8838235294117647\n",
      "9.3   0.8838235294117647\n",
      "9.4   0.8838235294117647\n",
      "9.5   0.8838235294117647\n",
      "9.600000000000001   0.8838235294117647\n",
      "9.700000000000001   0.8838235294117647\n",
      "9.8   0.8838235294117647\n",
      "9.9   0.8838235294117647\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    w1 = i * 0.1\n",
    "    print(w1,' ',get_score([w[0],w[1],w1],predict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0d32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
