{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72087f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMultipleChoice,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "import numpy as np\n",
    "# np.argmax([1,2,3,4])\n",
    "def softmax(x, axis=None):\n",
    "    x = np.array(x)\n",
    "    x = x - x.max(axis=axis, keepdims=True)\n",
    "    y = np.exp(x)\n",
    "    rst = y / y.sum(axis=axis, keepdims=True)\n",
    "    return rst.tolist()\n",
    "softmax([1,2])\n",
    "tokenizer = AutoTokenizer.from_pretrained('ethanyt/guwenbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af0713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/valid.jsonl','r') as f:\n",
    "    valid_json = f.readlines()\n",
    "    valid_json = [json.loads(e) for e in valid_json]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d83e1",
   "metadata": {},
   "source": [
    "### co_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afc959b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75625"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_translation_with_choice(translations, choice):\n",
    "    rst = 0\n",
    "    for c in choice:\n",
    "        if c in translations:\n",
    "            rst += 1\n",
    "    return rst\n",
    "def calculate_choice_in_choices(choice,choices):\n",
    "    choice_string = ''.join(choices)\n",
    "    rst = 0\n",
    "    for c in choice:\n",
    "        if c in choice_string:\n",
    "            rst += 1\n",
    "    return rst\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = []\n",
    "    for choice_id in range(len(choices)):\n",
    "        choice_score = calculate_translation_with_choice(valid_json[i]['translation'], choices[choice_id])\n",
    "        choice_score += calculate_choice_in_choices(choices[choice_id], choices)\n",
    "#         choice_score = sum(choice_score)\n",
    "        this_scores.append(choice_score)\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_dict['scores'] = this_scores\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['no_predict'] = int(np.argmin(this_scores))\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c817ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_num_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c09df146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': '昏暗的灯熄灭了又被重新点亮。',\n",
       " 'choices': ['渔灯灭复明', '残灯灭又然', '残灯暗复明', '残灯灭又明'],\n",
       " 'answer': 3,\n",
       " 'scores': [7, 8, 7, 8],\n",
       " 'predict': 1,\n",
       " 'no_predict': 0,\n",
       " 'true': False}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_num_predict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715fe30",
   "metadata": {},
   "source": [
    "### ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f03b4919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 10880/10880 [00:07<00:00, 1421.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/eval/ner.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for batch_idx in tqdm(range(len(rst['test_dataset']))):\n",
    "    origin_id = rst['test_dataset'][batch_idx]['origin_idx']\n",
    "    if origin_id not in all_scores:\n",
    "        all_scores[origin_id] = []\n",
    "    predicts = softmax(rst['test_result'].predictions[batch_idx],axis=-1)\n",
    "    labels = rst['test_result'].label_ids[batch_idx]\n",
    "    all_scores[origin_id].append(np.array(predicts)[np.where(labels!=-100)[0].tolist()][:,1].tolist())\n",
    "def multiple_list(l):\n",
    "    rst = 1\n",
    "    for e in l:\n",
    "        rst *= e\n",
    "    return rst\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = []\n",
    "    for choice_id in range(len(choices)):\n",
    "        choice_score = all_scores[i][choice_id]\n",
    "        choice_score = multiple_list(choice_score)\n",
    "#         choice_score = sum(choice_score)\n",
    "        this_scores.append(choice_score)\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_scores[co_num_predict[i]['no_predict']] = -100\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "202bbfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360294117647059"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce75147",
   "metadata": {},
   "source": [
    "save/ner/guwen/checkpoint-15000/pytorch_model.bin\n",
    "\n",
    "0.8224264705882353\n",
    "\n",
    "18000\n",
    "0.8220588235294117\n",
    "\n",
    "12000\n",
    "0.8319852941176471\n",
    "\n",
    "9000\n",
    "0.81875\n",
    "\n",
    "6000\n",
    "0.8183823529411764\n",
    "\n",
    "3000\n",
    "0.8338235294117647\n",
    "\n",
    "21000\n",
    "0.830514705882353\n",
    "\n",
    "24000\n",
    "0.8158088235294118\n",
    "\n",
    "27000\n",
    "0.8242647058823529\n",
    "\n",
    "30000\n",
    "0.8202205882352941\n",
    "\n",
    "33000\n",
    "0.8213235294117647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d72b7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cc101",
   "metadata": {},
   "source": [
    "### binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "199e87a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 24797/24797 [00:10<00:00, 2447.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8279411764705882"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/eval/binary.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for i in tqdm(range(len(rst['test_dataset']))):\n",
    "    idx = rst['test_dataset'][i]['origin_idx']\n",
    "    input_str = rst['test_dataset'][i]['input_ids']\n",
    "    input_str = tokenizer.decode(input_str)\n",
    "    input_str = input_str.split('[SEP]')\n",
    "    if idx not in all_scores:\n",
    "        all_scores[idx] = {}\n",
    "    all_scores[idx][input_str[1].replace(' ','')] = softmax(rst['test_result'].predictions[i].tolist())\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = []\n",
    "    for choice in choices:\n",
    "        choice_score = 0\n",
    "        for k in all_scores[i]:\n",
    "            if k in choice:\n",
    "                choice_score += all_scores[i][k][1]\n",
    "        this_scores.append(choice_score)\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_scores[co_num_predict[i]['no_predict']] = -100\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432277c",
   "metadata": {},
   "source": [
    "0.8172794117647059\n",
    "\n",
    "3000\n",
    "0.8268382352941176\n",
    "\n",
    "6000\n",
    "0.8180147058823529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69ee8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dee95f",
   "metadata": {},
   "source": [
    "### seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21d24b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 2720/2720 [00:00<00:00, 37922.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8746323529411765"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/eval/seq.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for i in tqdm(range(len(rst['test_dataset']))):\n",
    "    idx = i\n",
    "    all_scores[idx] = softmax(rst['test_result'].predictions[i].tolist())\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = all_scores[i]\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_scores[co_num_predict[i]['no_predict']] = -100\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0809019",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ac0f3",
   "metadata": {},
   "source": [
    "### ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e6672fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9308823529411765\n"
     ]
    }
   ],
   "source": [
    "oracle_true = [binary_predict[i]['true'] or ner_predict[i]['true'] or seq_predict[i]['true'] for i in range(len(ner_predict))]\n",
    "oracle_true = sum(oracle_true) / len(oracle_true)\n",
    "print(oracle_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09761171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8775735294117647"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [1,0.1,1.6]\n",
    "predict_list = [ner_predict,binary_predict,seq_predict]\n",
    "ensemble_predict = []\n",
    "def get_score(w,predict_list):\n",
    "    ensemble_predict = []\n",
    "    for i in range(len(predict_list[0])):\n",
    "        ensemble_predict.append(predict_list[0][i].copy())\n",
    "        ensemble_predict[-1]['scores'] = [np.array(predict_list[each_ensemble][i]['scores']) * w[each_ensemble] \n",
    "                                          for each_ensemble in range(len(predict_list))]\n",
    "        ensemble_predict[-1]['scores'] = sum(ensemble_predict[-1]['scores']).tolist()\n",
    "        ensemble_predict[-1]['predict'] = np.argmax(ensemble_predict[-1]['scores'])\n",
    "        ensemble_predict[-1]['true'] = (ensemble_predict[-1]['predict'] == ensemble_predict[-1]['answer'])\n",
    "    return np.sum([int(e['true']) for e in ensemble_predict]) / len(ensemble_predict)\n",
    "get_score(w,predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75a62815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0   0.8580882352941176\n",
      "0.1   0.8801470588235294\n",
      "0.2   0.88125\n",
      "0.30000000000000004   0.8849264705882353\n",
      "0.4   0.8852941176470588\n",
      "0.5   0.8849264705882353\n",
      "0.6000000000000001   0.8871323529411764\n",
      "0.7000000000000001   0.8856617647058823\n",
      "0.8   0.8863970588235294\n",
      "0.9   0.8871323529411764\n",
      "1.0   0.8856617647058823\n",
      "1.1   0.8856617647058823\n",
      "1.2000000000000002   0.8863970588235294\n",
      "1.3   0.8863970588235294\n",
      "1.4000000000000001   0.8871323529411764\n",
      "1.5   0.8867647058823529\n",
      "1.6   0.8871323529411764\n",
      "1.7000000000000002   0.8871323529411764\n",
      "1.8   0.8867647058823529\n",
      "1.9000000000000001   0.8867647058823529\n",
      "2.0   0.8867647058823529\n",
      "2.1   0.8863970588235294\n",
      "2.2   0.8863970588235294\n",
      "2.3000000000000003   0.8863970588235294\n",
      "2.4000000000000004   0.8863970588235294\n",
      "2.5   0.8856617647058823\n",
      "2.6   0.8856617647058823\n",
      "2.7   0.8856617647058823\n",
      "2.8000000000000003   0.8856617647058823\n",
      "2.9000000000000004   0.8856617647058823\n",
      "3.0   0.8856617647058823\n",
      "3.1   0.8856617647058823\n",
      "3.2   0.8856617647058823\n",
      "3.3000000000000003   0.8856617647058823\n",
      "3.4000000000000004   0.8852941176470588\n",
      "3.5   0.8852941176470588\n",
      "3.6   0.8852941176470588\n",
      "3.7   0.8852941176470588\n",
      "3.8000000000000003   0.8849264705882353\n",
      "3.9000000000000004   0.8849264705882353\n",
      "4.0   0.8849264705882353\n",
      "4.1000000000000005   0.8849264705882353\n",
      "4.2   0.8849264705882353\n",
      "4.3   0.8845588235294117\n",
      "4.4   0.8845588235294117\n",
      "4.5   0.8845588235294117\n",
      "4.6000000000000005   0.8845588235294117\n",
      "4.7   0.8841911764705882\n",
      "4.800000000000001   0.8841911764705882\n",
      "4.9   0.8841911764705882\n",
      "5.0   0.8841911764705882\n",
      "5.1000000000000005   0.8841911764705882\n",
      "5.2   0.8841911764705882\n",
      "5.300000000000001   0.8841911764705882\n",
      "5.4   0.8841911764705882\n",
      "5.5   0.8841911764705882\n",
      "5.6000000000000005   0.8841911764705882\n",
      "5.7   0.8838235294117647\n",
      "5.800000000000001   0.8838235294117647\n",
      "5.9   0.8838235294117647\n",
      "6.0   0.8838235294117647\n",
      "6.1000000000000005   0.8838235294117647\n",
      "6.2   0.8838235294117647\n",
      "6.300000000000001   0.8838235294117647\n",
      "6.4   0.8838235294117647\n",
      "6.5   0.8838235294117647\n",
      "6.6000000000000005   0.8838235294117647\n",
      "6.7   0.8838235294117647\n",
      "6.800000000000001   0.8838235294117647\n",
      "6.9   0.8838235294117647\n",
      "7.0   0.8838235294117647\n",
      "7.1000000000000005   0.8838235294117647\n",
      "7.2   0.8838235294117647\n",
      "7.300000000000001   0.8838235294117647\n",
      "7.4   0.8838235294117647\n",
      "7.5   0.8838235294117647\n",
      "7.6000000000000005   0.8838235294117647\n",
      "7.7   0.8838235294117647\n",
      "7.800000000000001   0.8838235294117647\n",
      "7.9   0.8838235294117647\n",
      "8.0   0.8838235294117647\n",
      "8.1   0.8838235294117647\n",
      "8.200000000000001   0.8838235294117647\n",
      "8.3   0.8838235294117647\n",
      "8.4   0.8838235294117647\n",
      "8.5   0.8838235294117647\n",
      "8.6   0.8838235294117647\n",
      "8.700000000000001   0.8838235294117647\n",
      "8.8   0.8838235294117647\n",
      "8.9   0.8838235294117647\n",
      "9.0   0.8838235294117647\n",
      "9.1   0.8838235294117647\n",
      "9.200000000000001   0.8838235294117647\n",
      "9.3   0.8838235294117647\n",
      "9.4   0.8838235294117647\n",
      "9.5   0.8838235294117647\n",
      "9.600000000000001   0.8838235294117647\n",
      "9.700000000000001   0.8838235294117647\n",
      "9.8   0.8838235294117647\n",
      "9.9   0.8838235294117647\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    w1 = i * 0.1\n",
    "    print(w1,' ',get_score([w[0],w[1],w1],predict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0d32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
