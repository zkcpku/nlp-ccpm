{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72087f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMultipleChoice,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "import numpy as np\n",
    "# np.argmax([1,2,3,4])\n",
    "def softmax(x, axis=None):\n",
    "    x = np.array(x)\n",
    "    x = x - x.max(axis=axis, keepdims=True)\n",
    "    y = np.exp(x)\n",
    "    rst = y / y.sum(axis=axis, keepdims=True)\n",
    "    return rst.tolist()\n",
    "softmax([1,2])\n",
    "tokenizer = AutoTokenizer.from_pretrained('ethanyt/guwenbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af0713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/valid.jsonl','r') as f:\n",
    "    valid_json = f.readlines()\n",
    "    valid_json = [json.loads(e) for e in valid_json]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38378e",
   "metadata": {},
   "source": [
    "### co_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c17f58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_argmin(l):\n",
    "    min_l = min(l)\n",
    "    return [i for i in range(len(l)) if l[i] == min_l]\n",
    "def multi_argmax(l):\n",
    "    max_l = max(l)\n",
    "    return [i for i in range(len(l)) if l[i] == max_l]\n",
    "def choice_cooccurrence(choices):\n",
    "    num = len(choices)\n",
    "    choices_return = []\n",
    "    scores = [0] * num\n",
    "    choice_tokens = [[] for _ in range(num)]\n",
    "    for i, choice in enumerate(choices):\n",
    "        choices_return.append(choice)\n",
    "        choice_tokens[i] = choice\n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            if i == j:\n",
    "                continue\n",
    "            for choice_tokens_id in range(len(choice_tokens[i])):\n",
    "                if choice_tokens[i][choice_tokens_id] == choice_tokens[i][choice_tokens_id]:\n",
    "                    scores[i] += 1\n",
    "    min_choice = multi_argmin(scores)\n",
    "    return scores\n",
    "    return min_choice\n",
    "    if len(min_choice) > 3:\n",
    "        return choices_return\n",
    "    for i in min_choice:\n",
    "        choices_return[i] = ''\n",
    "    return choices_return\n",
    "def choice_cooccurrence_no_position(choices):\n",
    "    num = len(choices)\n",
    "    choices_return = []\n",
    "    scores = [0] * num\n",
    "    choice_tokens = [[] for _ in range(num)]\n",
    "    for i, choice in enumerate(choices):\n",
    "        choices_return.append(choice)\n",
    "        for c in choice:\n",
    "            if c in choice_tokens[i]:\n",
    "                continue\n",
    "            choice_tokens[i].append(c)\n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            if i == j:\n",
    "                continue\n",
    "            for c in choice_tokens[i]:\n",
    "                if c in choice_tokens[j]:\n",
    "                    scores[i] += 1\n",
    "    min_choice = multi_argmin(scores)\n",
    "    return min_choice\n",
    "    if len(min_choice) > 3:\n",
    "        return choices_return\n",
    "    for i in min_choice:\n",
    "        choices_return[i] = ''\n",
    "    return choices_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2eebd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['渔灯灭复明', '残灯灭又然', '残灯暗复明', '残灯灭又明'], [0, 1, 2], [15, 15, 15, 15])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_json[0]['choices'],choice_cooccurrence_no_position(valid_json[0]['choices']),choice_cooccurrence(valid_json[0]['choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8882f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8768382352941176"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_translation_with_choice(translations, choice):\n",
    "    rst = 0\n",
    "    for c in choice:\n",
    "        if c in translations:\n",
    "            rst += 1\n",
    "    return rst\n",
    "def calculate_choice_in_choices(choice,choices):\n",
    "    rst = 0\n",
    "    for c in choice:\n",
    "        for other_choice in choices:\n",
    "            if choice == other_choice:\n",
    "                continue\n",
    "            if c in other_choice:\n",
    "                rst += 1\n",
    "    return rst\n",
    "def calculate_choice_in_position_choices(choice,choices):\n",
    "    rst = 0\n",
    "    for c_id in range(len(choice)):\n",
    "        c = choice[c_id]\n",
    "        for other_choice in choices:\n",
    "            if choice == other_choice:\n",
    "                continue\n",
    "            other_c = other_choice[c_id]\n",
    "            if c == other_c:\n",
    "                rst += 1\n",
    "    return rst\n",
    "    \n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "#     choices = choice_cooccurrence(choices)\n",
    "    this_scores = []\n",
    "    for choice_id in range(len(choices)):\n",
    "        choice_score = calculate_translation_with_choice(valid_json[i]['translation'], choices[choice_id])\n",
    "        choice_score += 0.5 * calculate_choice_in_choices(choices[choice_id], choices)\n",
    "#         choice_score += calculate_choice_in_position_choices(choices[choice_id], choices)\n",
    "#         choice_score = sum(choice_score)\n",
    "        this_scores.append(choice_score)\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_scores = softmax(this_scores)\n",
    "    this_dict['scores'] = this_scores\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['no_predict'] = multi_argmin(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6467167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_num_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67eff2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020955882352941175"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([e['answer'] in e['no_predict'] for e in co_num_predict]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c079bff5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': '便被选进了宫中。',\n",
       " 'choices': ['王孙归去好', '归去越王家', '归去葛洪家', '归去帝王家'],\n",
       " 'answer': 1,\n",
       " 'scores': [0.13447071068499755,\n",
       "  0.36552928931500245,\n",
       "  0.13447071068499755,\n",
       "  0.36552928931500245],\n",
       " 'predict': 1,\n",
       " 'no_predict': [0, 2],\n",
       " 'true': True}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_num_predict[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715fe30",
   "metadata": {},
   "source": [
    "### ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f03b4919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 10880/10880 [00:08<00:00, 1349.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/eval/ner.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for batch_idx in tqdm(range(len(rst['test_dataset']))):\n",
    "    origin_id = rst['test_dataset'][batch_idx]['origin_idx']\n",
    "    if origin_id not in all_scores:\n",
    "        all_scores[origin_id] = []\n",
    "    predicts = softmax(rst['test_result'].predictions[batch_idx],axis=-1)\n",
    "    labels = rst['test_result'].label_ids[batch_idx]\n",
    "    all_scores[origin_id].append(np.array(predicts)[np.where(labels!=-100)[0].tolist()][:,1].tolist())\n",
    "def multiple_list(l):\n",
    "    rst = 1\n",
    "    for e in l:\n",
    "        rst *= e\n",
    "    return rst\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = []\n",
    "    for choice_id in range(len(choices)):\n",
    "        choice_score = all_scores[i][choice_id]\n",
    "        choice_score = multiple_list(choice_score)\n",
    "#         choice_score = sum(choice_score)\n",
    "        this_scores.append(choice_score)\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_scores = np.array(this_scores)\n",
    "#     this_scores[co_num_predict[i]['no_predict']] += -100\n",
    "    this_scores = this_scores.tolist()\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "202bbfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8319852941176471"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce75147",
   "metadata": {},
   "source": [
    "save/ner/guwen/checkpoint-15000/pytorch_model.bin\n",
    "\n",
    "0.8224264705882353\n",
    "\n",
    "18000\n",
    "0.8220588235294117\n",
    "\n",
    "12000\n",
    "0.8319852941176471\n",
    "\n",
    "9000\n",
    "0.81875\n",
    "\n",
    "6000\n",
    "0.8183823529411764\n",
    "\n",
    "3000\n",
    "0.8338235294117647\n",
    "\n",
    "21000\n",
    "0.830514705882353\n",
    "\n",
    "24000\n",
    "0.8158088235294118\n",
    "\n",
    "27000\n",
    "0.8242647058823529\n",
    "\n",
    "30000\n",
    "0.8202205882352941\n",
    "\n",
    "33000\n",
    "0.8213235294117647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d72b7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cc101",
   "metadata": {},
   "source": [
    "### binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "199e87a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 24797/24797 [00:09<00:00, 2538.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8268382352941176"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/eval/binary.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for i in tqdm(range(len(rst['test_dataset']))):\n",
    "    idx = rst['test_dataset'][i]['origin_idx']\n",
    "    input_str = rst['test_dataset'][i]['input_ids']\n",
    "    input_str = tokenizer.decode(input_str)\n",
    "    input_str = input_str.split('[SEP]')\n",
    "    if idx not in all_scores:\n",
    "        all_scores[idx] = {}\n",
    "    all_scores[idx][input_str[1].replace(' ','')] = softmax(rst['test_result'].predictions[i].tolist())\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = []\n",
    "    for choice in choices:\n",
    "        choice_score = 0\n",
    "        for k in all_scores[i]:\n",
    "            if k in choice:\n",
    "                choice_score += all_scores[i][k][1]\n",
    "        this_scores.append(choice_score)\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_scores = np.array(this_scores)\n",
    "#     this_scores[co_num_predict[i]['no_predict']] += -100\n",
    "    this_scores = this_scores.tolist()\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432277c",
   "metadata": {},
   "source": [
    "0.8172794117647059\n",
    "\n",
    "3000\n",
    "0.8268382352941176\n",
    "\n",
    "6000\n",
    "0.8180147058823529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "69ee8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dee95f",
   "metadata": {},
   "source": [
    "### seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "21d24b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 2720/2720 [00:00<00:00, 32867.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8830882352941176"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('predict/final/eval/seq.pkl','rb') as f:\n",
    "    rst = pickle.load(f)\n",
    "all_scores = {}\n",
    "for i in tqdm(range(len(rst['test_dataset']))):\n",
    "    idx = i\n",
    "    all_scores[idx] = softmax(rst['test_result'].predictions[i].tolist())\n",
    "\n",
    "predict_valid_json = []\n",
    "for i in range(len(valid_json)):\n",
    "    choices = valid_json[i]['choices']\n",
    "    this_scores = all_scores[i]\n",
    "    this_dict = {k:valid_json[i][k] for k in valid_json[i]}\n",
    "    this_scores = np.array(this_scores)\n",
    "#     this_scores[co_num_predict[i]['no_predict']] += -100\n",
    "    this_scores = this_scores.tolist()\n",
    "    this_dict['scores'] = softmax(this_scores)\n",
    "    this_dict['predict'] = np.argmax(this_scores)\n",
    "    this_dict['true'] = (this_dict['predict'] == this_dict['answer'])\n",
    "    predict_valid_json.append(this_dict)\n",
    "np.sum([int(e['true']) for e in predict_valid_json]) / len(predict_valid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a0809019",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_predict = predict_valid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ac0f3",
   "metadata": {},
   "source": [
    "### ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8e6672fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808823529411764\n"
     ]
    }
   ],
   "source": [
    "oracle_true = [binary_predict[i]['true'] or ner_predict[i]['true'] or seq_predict[i]['true'] or co_num_predict[i]['true'] for i in range(len(ner_predict))]\n",
    "oracle_true = sum(oracle_true) / len(oracle_true)\n",
    "print(oracle_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "09761171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [1,0.1,1.5,2]\n",
    "predict_list = [ner_predict,binary_predict,seq_predict,co_num_predict]\n",
    "ensemble_predict = []\n",
    "def get_score(w,predict_list):\n",
    "    ensemble_predict = []\n",
    "    for i in range(len(predict_list[0])):\n",
    "        ensemble_predict.append(predict_list[0][i].copy())\n",
    "        ensemble_predict[-1]['scores'] = [np.array(predict_list[each_ensemble][i]['scores']) * w[each_ensemble] \n",
    "                                          for each_ensemble in range(len(predict_list))]\n",
    "        ensemble_predict[-1]['scores'] = sum(ensemble_predict[-1]['scores']).tolist()\n",
    "        ensemble_predict[-1]['predict'] = np.argmax(ensemble_predict[-1]['scores'])\n",
    "        ensemble_predict[-1]['true'] = (ensemble_predict[-1]['predict'] == ensemble_predict[-1]['answer'])\n",
    "    return np.sum([int(e['true']) for e in ensemble_predict]) / len(ensemble_predict)\n",
    "get_score(w,predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75a62815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0   0.875\n",
      "0.1   0.8919117647058824\n",
      "0.2   0.8926470588235295\n",
      "0.30000000000000004   0.8948529411764706\n",
      "0.4   0.8952205882352942\n",
      "0.5   0.8944852941176471\n",
      "0.6000000000000001   0.8944852941176471\n",
      "0.7000000000000001   0.8955882352941177\n",
      "0.8   0.8952205882352942\n",
      "0.9   0.8959558823529412\n",
      "1.0   0.8952205882352942\n",
      "1.1   0.8952205882352942\n",
      "1.2000000000000002   0.8952205882352942\n",
      "1.3   0.8952205882352942\n",
      "1.4000000000000001   0.8959558823529412\n",
      "1.5   0.8966911764705883\n",
      "1.6   0.8959558823529412\n",
      "1.7000000000000002   0.8959558823529412\n",
      "1.8   0.8955882352941177\n",
      "1.9000000000000001   0.8955882352941177\n",
      "2.0   0.8955882352941177\n",
      "2.1   0.8955882352941177\n",
      "2.2   0.8952205882352942\n",
      "2.3000000000000003   0.8952205882352942\n",
      "2.4000000000000004   0.8952205882352942\n",
      "2.5   0.8948529411764706\n",
      "2.6   0.8948529411764706\n",
      "2.7   0.8948529411764706\n",
      "2.8000000000000003   0.8948529411764706\n",
      "2.9000000000000004   0.8948529411764706\n",
      "3.0   0.8948529411764706\n",
      "3.1   0.8948529411764706\n",
      "3.2   0.8944852941176471\n",
      "3.3000000000000003   0.8944852941176471\n",
      "3.4000000000000004   0.8944852941176471\n",
      "3.5   0.8941176470588236\n",
      "3.6   0.8941176470588236\n",
      "3.7   0.8941176470588236\n",
      "3.8000000000000003   0.8941176470588236\n",
      "3.9000000000000004   0.8941176470588236\n",
      "4.0   0.8941176470588236\n",
      "4.1000000000000005   0.89375\n",
      "4.2   0.89375\n",
      "4.3   0.89375\n",
      "4.4   0.89375\n",
      "4.5   0.89375\n",
      "4.6000000000000005   0.89375\n",
      "4.7   0.89375\n",
      "4.800000000000001   0.89375\n",
      "4.9   0.89375\n",
      "5.0   0.8933823529411765\n",
      "5.1000000000000005   0.8933823529411765\n",
      "5.2   0.8933823529411765\n",
      "5.300000000000001   0.8933823529411765\n",
      "5.4   0.8933823529411765\n",
      "5.5   0.8933823529411765\n",
      "5.6000000000000005   0.8933823529411765\n",
      "5.7   0.8933823529411765\n",
      "5.800000000000001   0.8933823529411765\n",
      "5.9   0.8933823529411765\n",
      "6.0   0.8933823529411765\n",
      "6.1000000000000005   0.8933823529411765\n",
      "6.2   0.8933823529411765\n",
      "6.300000000000001   0.8933823529411765\n",
      "6.4   0.8933823529411765\n",
      "6.5   0.8933823529411765\n",
      "6.6000000000000005   0.8933823529411765\n",
      "6.7   0.8933823529411765\n",
      "6.800000000000001   0.8933823529411765\n",
      "6.9   0.8933823529411765\n",
      "7.0   0.8933823529411765\n",
      "7.1000000000000005   0.89375\n",
      "7.2   0.89375\n",
      "7.300000000000001   0.89375\n",
      "7.4   0.89375\n",
      "7.5   0.89375\n",
      "7.6000000000000005   0.89375\n",
      "7.7   0.89375\n",
      "7.800000000000001   0.89375\n",
      "7.9   0.89375\n",
      "8.0   0.89375\n",
      "8.1   0.89375\n",
      "8.200000000000001   0.89375\n",
      "8.3   0.89375\n",
      "8.4   0.89375\n",
      "8.5   0.89375\n",
      "8.6   0.89375\n",
      "8.700000000000001   0.89375\n",
      "8.8   0.89375\n",
      "8.9   0.89375\n",
      "9.0   0.89375\n",
      "9.1   0.89375\n",
      "9.200000000000001   0.89375\n",
      "9.3   0.89375\n",
      "9.4   0.89375\n",
      "9.5   0.89375\n",
      "9.600000000000001   0.89375\n",
      "9.700000000000001   0.89375\n",
      "9.8   0.89375\n",
      "9.9   0.89375\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    w1 = i * 0.1\n",
    "    print(w1,' ',get_score([w[0],w[1],w1],predict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0d32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
